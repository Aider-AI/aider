import sys
import os
import json

# Ensure the main aider directory is in the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from aider.coders.agent_coder import AgentCoder
from aider.models import Model
from aider.io import InputOutput

def main():
    io = InputOutput(pretty=True, yes=True, encoding="utf-8")
    main_model = Model("gemini/gemini-2.5-flash-preview-05-20")
    
    # More complex task for planner agent
    core_task = (
        "You are tasked with developing a small utility to manage a list of tasks.\n"
        "1. Create a Python file `agent_test_temp_output/task_manager.py`.\n"
        "2. This file should define a class `TaskManager` with the following methods:\n"
        "    * `__init__(self)`: Initializes an empty list to store tasks.\n"
        "    * `add_task(self, description: str)`: Adds a new task (string) to the list.\n"
        "    * `list_tasks(self) -> list[str]`: Returns the list of tasks.\n"
        "    * `mark_task_complete(self, task_index: int) -> bool`: Marks a task as complete by appending \" [DONE]\". Returns `True` if valid, `False` otherwise. (0-based index).\n"
        "3. Create `agent_test_temp_output/test_task_manager.py` with comprehensive pytest unit tests for all methods. Cover edge cases like adding empty tasks, listing when empty, marking non-existent tasks, or marking already completed tasks."
    )

    # Create a dummy args object to pass to AgentCoder
    class Args:
        def __init__(self):
            self.agent_hierarchical_planning = 'full_two_level' # or 'deliverables_only' or 'none'
            self.agent_generate_tests = 'all_code' # 'descriptions', 'all_code', or 'none'
            self.agent_max_decomposition_depth = 10
            self.agent_output_plan_only = False
            self.agent_enable_planner_executor_arch = False # Keep simple for this test
            self.agent_planner_model = None
            self.agent_executor_model = None
            self.agent_headless = True # Run without interactive prompts for approval
            self.agent_auto_approve = True # Implied by headless, but good to be explicit
            self.agent_web_search = "never" # No web search for this test
            self.search_mode = False # Disable general search enhancer
            self.agent_clarify_task = False # ADDED: Allow skipping clarification for tests

    args = Args()

    agent = AgentCoder(
        main_model=main_model,
        io=io,
        repo=None,
        from_coder=None,
        initial_task=core_task,
        stream=False,
        args=args, # Pass the args object
        # These are now effectively controlled by args or have defaults in AgentCoder
        # planner_mode=True, 
        # debugger_mode=True,
        # coder_mode=True, 
    )
    agent.verbose = True # Enable verbose LLM I/O logging

    try:
        io.tool_output(f"Planner/Debugger/Coder Agent initialized with task: {core_task}")
        agent.run()
        print("Planner/Debugger/Coder Agent run completed.")
        
        print("\nAGENT FINAL PLAN:\n")
        if agent.plan:
            try:
                print(json.dumps(agent.plan, indent=2, default=str))
            except TypeError:
                print(str(agent.plan))
        else:
            print("No plan was generated by the agent.")

        print("\nAGENT SUGGESTED TEST COMMAND:\n")
        if agent.agent_test_command:
            print(agent.agent_test_command)
        else:
            print("No test command was suggested by the agent.")

    except Exception as e:
        print(f"An error occurred during planner/debugger/coder agent execution: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    main() 