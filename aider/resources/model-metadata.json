{
    "deepseek-reasoner": {
        "max_tokens": 8192,
        "max_input_tokens": 64000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000055,
        "input_cost_per_token_cache_hit": 0.00000014,
        "cache_read_input_token_cost": 0.00000014,
        "cache_creation_input_token_cost": 0.0,
        "output_cost_per_token": 0.00000219,
        "litellm_provider": "deepseek",
        "mode": "chat",
        //"supports_function_calling": true, 
        "supports_assistant_prefill": true,
        //"supports_tool_choice": true,
        "supports_prompt_caching": true
    },
    "openrouter/deepseek/deepseek-r1": {
        "max_tokens": 8192,
        "max_input_tokens": 64000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000055,
        "input_cost_per_token_cache_hit": 0.00000014,
        "cache_read_input_token_cost": 0.00000014,
        "cache_creation_input_token_cost": 0.0,
        "output_cost_per_token": 0.00000219,
        "litellm_provider": "openrouter",
        "mode": "chat",
        //"supports_function_calling": true, 
        "supports_assistant_prefill": true,
        //"supports_tool_choice": true,
        "supports_prompt_caching": true
    },
    "openrouter/deepseek/deepseek-r1:free": {
        "max_tokens": 8192,
        "max_input_tokens": 64000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0,
        "input_cost_per_token_cache_hit": 0.0,
        "cache_read_input_token_cost": 0.00,
        "cache_creation_input_token_cost": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat",
        //"supports_function_calling": true, 
        "supports_assistant_prefill": true,
        //"supports_tool_choice": true,
        "supports_prompt_caching": true
    },
    "openrouter/deepseek/deepseek-chat:free": {
        "max_tokens": 8192,
        "max_input_tokens": 64000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.0,
        "input_cost_per_token_cache_hit": 0.0,
        "cache_read_input_token_cost": 0.00,
        "cache_creation_input_token_cost": 0.0,
        "output_cost_per_token": 0.0,
        "litellm_provider": "openrouter",
        "mode": "chat",
        //"supports_function_calling": true, 
        "supports_assistant_prefill": true,
        //"supports_tool_choice": true,
        "supports_prompt_caching": true
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
        "max_tokens": 160000,
        "max_input_tokens": 128000,
        "max_output_tokens": 20480,
        "litellm_provider": "fireworks_ai",
        "input_cost_per_token": 0.000008,
        "output_cost_per_token": 0.000008,
        "mode": "chat",
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
        "max_tokens": 128000,
        "max_input_tokens": 100000,
        "max_output_tokens": 8192,
        "litellm_provider": "fireworks_ai",
        "input_cost_per_token": 0.0000009,
        "output_cost_per_token": 0.0000009,
        "mode": "chat",
    },
    "o3-mini": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true
    },
    "openrouter/openai/o3-mini": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true
    },
    "openrouter/openai/o3-mini-high": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.0000011,
        "output_cost_per_token": 0.0000044,
        "cache_read_input_token_cost": 0.00000055,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true
    },
    "openrouter/openai/gpt-4o-mini": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000060,
        "input_cost_per_token_batches": 0.000000075,
        "output_cost_per_token_batches": 0.00000030,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true
    },
    "claude-3-7-sonnet-20250219": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "cache_creation_input_token_cost": 0.00000375,
        "cache_read_input_token_cost": 0.0000003,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-10-01",
        "supports_tool_choice": true
    },
    "anthropic/claude-3-7-sonnet-20250219": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "cache_creation_input_token_cost": 0.00000375,
        "cache_read_input_token_cost": 0.0000003,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-10-01",
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "cache_creation_input_token_cost": 0.00000375,
        "cache_read_input_token_cost": 0.0000003,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-10-01",
        "supports_tool_choice": true
    },
    "gpt-4.5-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000075,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 0.0000375,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "openai/gpt-4.5-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000075,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 0.0000375,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
}
