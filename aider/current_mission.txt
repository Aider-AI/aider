One thing i am missing though is to be able to change the model during a run
asside of using `--model gpt-4-1106-preview` (which should be the default now as it has way longer context, but also just more powerful and cheaper)
 i want to run a `/models` command and see something like:

Alias | Model | Input | Output
-- | -- | -- | --
4 | gpt-4-1106-preview | $0.01 / 1K tokens | $0.03 / 1K tokens
4v | gpt-4-1106-vision-preview | $0.01 / 1K tokens | $0.03 / 1K tokens
3 | gpt-3.5-turbo-1106 | $0.0010 / 1K tokens | $0.0020 / 1K tokens
px | ruu3f-perplexityai | $0.0 / with limits | $0.0 / with limits
--| Hopefully add more in the future | -- | --

and then be able to use `/model 3` or `/m 3` to quickly switch to the cheap gpt3.5 turbo

Switching between `/m 3` and `/m 4` would be super beneficial. 

Requirements:

* Add /models and /model commands (also /m short for /model)
  [x] First line should show the current model being used, then print out the models table
  [x] models dict should be imported from models_table
  [x] table should be with these headings in order: Alias, Model (key), Input Cost (str: input_cost+cost_desc), Input Cost (str: input_cost+cost_desc), Description (of the model)
* /model or /m {alias} to change model
  [x] should change the actual model used for api
  [x] should update the data displayed when checking /tokens
  [x] default model should be 4, `/m` without any model specified should toggle models 3 and 4
  
Thanks and all the best!
